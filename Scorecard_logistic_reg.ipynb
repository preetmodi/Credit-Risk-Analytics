{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNaxI/LgzKwY3Qmnz9Pk6Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetmodi/Credit-Risk-Analytics/blob/main/Scorecard_logistic_reg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo echo -ne '\\n' | sudo add-apt-repository ppa:alessandro-strada/ppa >/dev/null 2>&1 # note: >/dev/null 2>&1 is used to supress printing\n",
        "!sudo apt update >/dev/null 2>&1\n",
        "!sudo apt install google-drive-ocamlfuse >/dev/null 2>&1\n",
        "!google-drive-ocamlfuse\n",
        "!sudo apt-get install w3m >/dev/null 2>&1 # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop >/dev/null 2>&1 # to set default browser \n",
        "%cd /content\n",
        "!mkdir gdrive\n",
        "%cd gdrive\n",
        "!mkdir \"My Drive\"\n",
        "!google-drive-ocamlfuse \"/content/gdrive/My Drive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgACdi0SDOer",
        "outputId": "d272474e-e981-4f94-9113-3991f17494d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/xdg-open: 869: www-browser: not found\n",
            "/usr/bin/xdg-open: 869: links2: not found\n",
            "/usr/bin/xdg-open: 869: elinks: not found\n",
            "/usr/bin/xdg-open: 869: links: not found\n",
            "/usr/bin/xdg-open: 869: lynx: not found\n",
            "/usr/bin/xdg-open: 869: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=po0RjVlNj4Egyvf%2FJc04yV3TNXHn2jD0TAVfHNKFWTo'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=po0RjVlNj4Egyvf%2FJc04yV3TNXHn2jD0TAVfHNKFWTo\")\n",
            "/content\n",
            "/content/gdrive\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/CBravoR/scorecardpy\n",
        "\n",
        "%cd /content/gdrive/My Drive/Data/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWgPantPDlhZ",
        "outputId": "16014f18-ed81-4316-edb9-709ac9e2ad8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/CBravoR/scorecardpy\n",
            "  Cloning https://github.com/CBravoR/scorecardpy to /tmp/pip-req-build-szz39cai\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/CBravoR/scorecardpy /tmp/pip-req-build-szz39cai\n",
            "  Resolved https://github.com/CBravoR/scorecardpy to commit 03ec28470391e5c950580ad9ac4877ca33f05fce\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from scorecardpy==0.1.9.3) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.9/dist-packages (from scorecardpy==0.1.9.3) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from scorecardpy==0.1.9.3) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from scorecardpy==0.1.9.3) (1.2.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.9/dist-packages (from scorecardpy==0.1.9.3) (0.13.5)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.9/dist-packages (from scorecardpy==0.1.9.3) (0.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25.0->scorecardpy==0.1.9.3) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25.0->scorecardpy==0.1.9.3) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->scorecardpy==0.1.9.3) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->scorecardpy==0.1.9.3) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->scorecardpy==0.1.9.3) (3.1.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->scorecardpy==0.1.9.3) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->scorecardpy==0.1.9.3) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->scorecardpy==0.1.9.3) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->scorecardpy==0.1.9.3) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->scorecardpy==0.1.9.3) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->scorecardpy==0.1.9.3) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->scorecardpy==0.1.9.3) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->scorecardpy==0.1.9.3) (3.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy->scorecardpy==0.1.9.3) (1.16.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->scorecardpy==0.1.9.3) (3.15.0)\n",
            "Building wheels for collected packages: scorecardpy\n",
            "  Building wheel for scorecardpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scorecardpy: filename=scorecardpy-0.1.9.3-py3-none-any.whl size=59549 sha256=242923026a77c2bc9eacf6451c189f15c2284a6c4669dbed774d98da40e10079\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bpxfrjk8/wheels/61/36/7f/76fa329f36d896910f2251f5cfd54094c722e088b633e47f6f\n",
            "Successfully built scorecardpy\n",
            "Installing collected packages: scorecardpy\n",
            "Successfully installed scorecardpy-0.1.9.3\n",
            "/content/gdrive/My Drive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Package loading\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scorecardpy as sc\n",
        "from string import ascii_letters\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "%matplotlib inline\n",
        "seed = 251256517"
      ],
      "metadata": {
        "id": "WpdJ98mUDpnt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "OD9welLaDIkD",
        "outputId": "384aa5c4-9571-4bf2-c879-909e76b39058"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e5390b7ffa64>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import the files as Pandas datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_WoE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_woe.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_WoE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_woe.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# bankloan_data = pd.read_pickle('BankloanCleanNewVars.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_woe.csv'"
          ]
        }
      ],
      "source": [
        "# Import the files as Pandas datasets\n",
        "train_WoE = pd.read_csv('train_woe.csv')\n",
        "test_WoE = pd.read_csv('test_woe.csv')\n",
        "\n",
        "train_noWoE = pd.read_csv('train.csv')\n",
        "test_noWoE = pd.read_csv('test.csv')\n",
        "\n",
        "# Give breaks for WoE\n",
        "with open('breaks_adj.json', 'r') as f:\n",
        "    breaks_adj = json.load(f)\n",
        "# breaks_adj = {'Address': [1.0,2.0,8.0,17.0],\n",
        "#               'Age': [30.0,45.0,50.0],\n",
        "#               'Creddebt': [1.0, 6.0],\n",
        "#               'Employ': [4.0,14.0,22.0],\n",
        "#               'Income': [30.0,40.0,80.0,140.0],\n",
        "#               'Leverage': [8.0,16.0,22.0],\n",
        "#               'MonthlyLoad': [0.1,0.2,0.30000000000000004,0.7000000000000001],\n",
        "#               'OthDebt': [1.0,2.0,3.0],\n",
        "#               'OthDebtRatio': [0.01,0.05,0.07,0.09,0.14]\n",
        "#               }\n",
        "\n",
        "# Apply breaks.\n",
        "bins_adj = sc.woebin(train_noWoE, y=\"Default\",\n",
        "                     breaks_list=breaks_adj)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "logreg = LogisticRegressionCV(penalty='elasticnet', # Type of penalization l1 = lasso, l2 = ridge, elasticnet\n",
        "                                     Cs = 10,        # How many parameters to try. Can also be a vector with parameters to try.\n",
        "                                     tol=0.000001, # Tolerance for parameters\n",
        "                                     cv = 3,     # How many CV folds to try. 3 or 5 should be enough.\n",
        "                                     fit_intercept=True, # Use constant?\n",
        "                                     class_weight='balanced', # Weights, see below\n",
        "                                     random_state=20190301, # Random seed\n",
        "                                     max_iter=100, # Maximum iterations\n",
        "                                     verbose=2, # Show process. 1 is yes.\n",
        "                                     solver = 'saga', # How to optimize.\n",
        "                                     n_jobs = 2,      # Processes to use. Set to number of physical cores. \n",
        "                                     refit = True,     # If to retrain with the best parameter and all data after finishing.\n",
        "                                     l1_ratios = np.arange(0, 1.01, 0.1), # The LASSO / Ridge ratios.\n",
        "                                    )"
      ],
      "metadata": {
        "id": "2oDTloE9D2CC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "PturFW7HEq1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg.fit(X = train_WoE.iloc[:, 1:], # All rows and from the second var to end\n",
        "                    y = train_WoE['Default'] # The target\n",
        "                   )"
      ],
      "metadata": {
        "id": "2bizVZU3ETvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parameter Inference"
      ],
      "metadata": {
        "id": "cAHfP20CEoCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coef_df = pd.concat([pd.DataFrame({'column': train_WoE.columns[np.r_[1:6,7]]}), \n",
        "                    pd.DataFrame(np.transpose(logreg.coef_))],\n",
        "                    axis = 1\n",
        "                   )\n",
        "\n",
        "coef_df"
      ],
      "metadata": {
        "id": "a1VJHRYCEqSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg.intercept_"
      ],
      "metadata": {
        "id": "w2mTUhDqEu50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(logreg.l1_ratio_)\n",
        "print(logreg.C_)"
      ],
      "metadata": {
        "id": "o03cCY-kH9Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying on Test Set"
      ],
      "metadata": {
        "id": "pXhuhZccIDX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_class_test = logreg.predict(test_WoE.iloc[:, 1:].drop(columns=\"Income_woe\"))\n",
        "probs_test = logreg.predict_proba(test_WoE.iloc[:, 1:].drop(columns=\"Income_woe\"))\n",
        "print(probs_test[0:5], pred_class_test[0:5])"
      ],
      "metadata": {
        "id": "o9wQxIQoICdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix"
      ],
      "metadata": {
        "id": "thlZDS7qINDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# Calculate confusion matrix\n",
        "confusion_matrix_cs = confusion_matrix(y_true = test_WoE['Default'],\n",
        "                                        y_pred = pred_class_test)\n",
        "\n",
        "\n",
        "# Turn matrix to percentages\n",
        "confusion_matrix_cs = confusion_matrix_cs.astype('float') / confusion_matrix_cs.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Turn to dataframe\n",
        "df_cm = pd.DataFrame(\n",
        "        confusion_matrix_cs, index=['Non Defaulter', 'Defaulter'], \n",
        "        columns=['Non Defaulter', 'Defaulter'], \n",
        ")\n",
        "\n",
        "# Parameters of the image\n",
        "figsize = (10,7)\n",
        "fontsize=14\n",
        "\n",
        "# Create image\n",
        "fig = plt.figure(figsize=figsize)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt='.2f')\n",
        "\n",
        "# Make it nicer\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, \n",
        "                             ha='right', fontsize=fontsize)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45,\n",
        "                             ha='right', fontsize=fontsize)\n",
        "\n",
        "# Add labels\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "\n",
        "# Plot!\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q7141f4TIMRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Scorecard"
      ],
      "metadata": {
        "id": "ZL6h65q1IVMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loans_sc = sc.scorecard(bins_adj,         # bins from the WoE\n",
        "                           logreg,  # Trained logistic regression\n",
        "                           train_WoE.columns[np.r_[1:6,7]], # The column names in the trained LR\n",
        "                           points0=750, # Base points\n",
        "                           odds0=0.01, # Base odds bads:goods\n",
        "                           pdo=50\n",
        "                           ) # PDO "
      ],
      "metadata": {
        "id": "Oc5E-kAKIWZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loans_sc"
      ],
      "metadata": {
        "id": "z6JatiyCIe8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Credit Score"
      ],
      "metadata": {
        "id": "kB75YjWXIinO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = sc.scorecard_ply(train_noWoE, loans_sc, \n",
        "                               print_step=0)\n",
        "test_score = sc.scorecard_ply(test_noWoE, loans_sc, \n",
        "                               print_step=0)"
      ],
      "metadata": {
        "id": "5CXAm_hbIkZ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}